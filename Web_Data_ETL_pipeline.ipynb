{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuMY47c2r_5U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*ETL ---> Extract Transform Load*\n",
        "ETL pipleline is a systematic process used in data engineering to collect, transform and load the data from various sources on the internet into a structured and usable format for analysis and storage"
      ],
      "metadata": {
        "id": "uHCc8b05LYbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4 nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8snEfFytMDa1",
        "outputId": "18010df4-e01d-4f6e-8f5b-315c083060c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L6jmpiWAXRKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0LHgnSXXUfl",
        "outputId": "ee343298-83d0-4897-9a6e-3b73bb4a6783"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WebScraper:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "    def extract_text(self):\n",
        "        response = requests.get(self.url)\n",
        "        html_text = response.text\n",
        "        soup = BeautifulSoup(html_text, 'html.parser')\n",
        "        text = soup.get_text()\n",
        "        return text\n",
        "\n",
        "class TestProcessor:\n",
        "    def __init__(self, nltk_stopwords):\n",
        "      self.nltk_stopwords = nltk_stopwords\n",
        "    def tokenize_text(self, text):\n",
        "      words = text.split()\n",
        "      filtered_words = [word.lower() for word in words if word.isalpha() and word.lower() not in self.nltk_stopwords]\n",
        "      return filtered_words\n",
        "\n",
        "class ETLPipeline:\n",
        "   def __init__(self, url):\n",
        "    self.url = url\n",
        "    self.nltk_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "   def run(self):\n",
        "    scraper = WebScraper(self.url)\n",
        "    article_text = scraper.extract_text()\n",
        "    test_processor = TestProcessor(self.nltk_stopwords)\n",
        "    filtered_words = test_processor.tokenize_text(article_text)\n",
        "    word_count = Counter(filtered_words)\n",
        "    df = pd.DataFrame(word_count.items(), columns=['word', 'count'])\n",
        "    df = df.sort_values(by='count', ascending=False)\n",
        "    return df\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    url = 'https://timesofindia.indiatimes.com/india'\n",
        "    etl_pipeline = ETLPipeline(url)\n",
        "    df = etl_pipeline.run()\n",
        "    print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTD5V8XmXoGM",
        "outputId": "b03571cd-32fe-4795-d2bb-57820aefbbef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            word  count\n",
            "86          modi     10\n",
            "0          india      9\n",
            "85            pm      9\n",
            "195           rs      8\n",
            "10         kumbh      8\n",
            "..           ...    ...\n",
            "278       remark      1\n",
            "277  proceedings      1\n",
            "276    privilege      1\n",
            "274   shivrajbjp      1\n",
            "645  information      1\n",
            "\n",
            "[646 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VSccYAhOg9lC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}